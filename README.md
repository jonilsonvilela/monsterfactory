üî• Monster Factory üî•
Sua f√°brica de assistentes inteligentes para automa√ß√£o de tarefas jur√≠dicas.
üìñ Vis√£o Geral
Monster Factory √© uma plataforma de automa√ß√£o inteligente constru√≠da para o setor jur√≠dico. O seu core consiste numa arquitetura de "f√°brica" projetada para criar, gerir e executar "monstros": assistentes de IA altamente especializados, cada um treinado para uma tarefa jur√≠dica espec√≠fica.

Utilizando um poderoso modelo de linguagem (Google Gemini) e a t√©cnica de Gera√ß√£o Aumentada por Recupera√ß√£o (RAG), a plataforma analisa documentos complexos, como decis√µes judiciais em .pdf, e automatiza processos repetitivos, como o preenchimento de s√∫mulas, a gera√ß√£o de relat√≥rios e, futuramente, a elabora√ß√£o de pareceres e comunica√ß√µes.

O projeto foi desenhado com base em dois pilares: modularidade e escalabilidade. A arquitetura de assistentes isolados permite que novos "monstros" sejam desenvolvidos e integrados √† f√°brica sem qualquer altera√ß√£o na infraestrutura central.

‚ú® Funcionalidades Principais
Arquitetura de F√°brica de Monstros: Desenvolva e adicione novos assistentes de IA como m√≥dulos independentes. Cada "monstro" tem a sua pr√≥pria l√≥gica, prompts e schemas, garantindo um isolamento completo.

An√°lise Inteligente com RAG: Fa√ßa o upload de documentos .pdf e o sistema ir√° contextualizar a an√°lise utilizando uma base de conhecimento vetorial (RAG) constru√≠da a partir de documentos internos, como a "Pol√≠tica Recursal".

Preenchimento Autom√°tico de Formul√°rios: A IA preenche formul√°rios web complexos com os dados extra√≠dos dos documentos, minimizando o trabalho manual.

Valida√ß√£o Humana e Feedback Loop: Permite que o utilizador revise e corrija os dados extra√≠dos. Cada corre√ß√£o √© armazenada numa base de dados SQLite (feedback.db), criando um ciclo de feedback valioso para o re-treino e aprimoramento cont√≠nuo dos modelos.

Gera√ß√£o de Documentos: Ap√≥s a valida√ß√£o humana, o sistema gera automaticamente documentos .docx e .pdf a partir de templates pr√©-definidos.

üèóÔ∏è Arquitetura do Sistema
O projeto opera sobre uma arquitetura de microsservi√ßos orquestrada pelo Docker Compose, garantindo que cada componente funcione de forma isolada e eficiente.

1. Frontend (index.html):
Uma Single-Page Application (SPA) constru√≠da com HTML5, TailwindCSS e JavaScript puro. √â a interface do utilizador, por onde as tarefas s√£o iniciadas.

2. Orquestrador Principal / API (main.py):
O cora√ß√£o da f√°brica. Este servi√ßo FastAPI n√£o cont√©m l√≥gica de neg√≥cio dos assistentes. As suas responsabilidades s√£o:

Receber as requisi√ß√µes da API.

Gerir o upload de ficheiros.

Identificar qual "monstro" (assistente) deve ser ativado com base no assistant_type.

Utilizar importlib para carregar dinamicamente o m√≥dulo do assistente solicitado.

Executar a l√≥gica do assistente em segundo plano (asyncio).

Gerir o estado dos jobs e responder aos pedidos de status.

Interagir com a base de dados de feedback.

3. Assistentes Modulares (assistants/):
Esta √© a "linha de produ√ß√£o" da f√°brica. Cada subdiret√≥rio √© um "monstro" autocontido.

Exemplo: assistants/dispensa_assistant/:

logic.py: Cont√©m todo o fluxo de trabalho: extra√ß√£o de texto do PDF, consulta √† base de vetores (RAG) e a chamada √† API do LLM.

prompt.py: Define as instru√ß√µes exatas ("personalidade" e "ordens") que s√£o dadas √† IA.

schema.py: Define o formato JSON exato que a IA deve retornar como resposta.

4. Servi√ßo de Gera√ß√£o (generator_service.py):
Um microsservi√ßo FastAPI especializado. Ele recebe uma estrutura de dados JSON e a utiliza para preencher um template .docx (docxtpl) e depois o converte para .pdf (usando LibreOffice), disponibilizando ambos para download.

5. Servi√ßo de Treinamento (training_service.py):
Outro microsservi√ßo FastAPI que serve um prop√≥sito √∫nico: expor um endpoint que consulta a base de dados feedback.db e retorna os dados formatados em JSONL, prontos para serem usados em processos de fine-tuning de modelos de linguagem.

üõ†Ô∏è Stack Tecnol√≥gica
Backend: Python 3.11, FastAPI

Frontend: HTML5, TailwindCSS, JavaScript (Vanilla)

IA & RAG: LangChain, Google Gemini, HuggingFace Embeddings (rufimelo/Legal-BERTimbau-sts-large), Faiss (Vector Store)

Gera√ß√£o de Documentos: docxtpl, LibreOffice (via Docker)

Base de Dados (Feedback): SQLite

Infraestrutura: Docker, Docker Compose

üöÄ Guia de Instala√ß√£o e Execu√ß√£o
Para p√¥r a f√°brica a funcionar, √© necess√°rio ter o Docker e o Docker Compose instalados.

Passo 1: Clonar o Reposit√≥rio

Bash

git clone https://github.com/seu-usuario/monster-factory.git
cd monster-factory
Passo 2: Configurar a Chave da API
Crie um ficheiro .env na raiz do projeto e adicione a sua chave da API do Google Gemini.

Snippet de c√≥digo

# .env
GEMINI_API_KEY="SUA_CHAVE_DE_API_AQUI"
Passo 3: Adicionar a Base de Conhecimento
Coloque o documento que servir√° de base para o sistema RAG na raiz do projeto, com o nome Pol√≠tica Recursal.pdf.

Passo 4: Construir a Base Vetorial (Passo Cr√≠tico)
A IA precisa que o conhecimento do PDF seja convertido para um formato que ela entenda (vetores). Cri√°mos um script para automatizar isto.

Primeiro, inicie os servi√ßos uma vez para construir as imagens Docker com todas as depend√™ncias:

Bash

docker-compose up --build -d
Em seguida, execute o script de cria√ß√£o da base de vetores dentro do contentor da api:

Bash

docker-compose exec api python create_vector_store.py
Este comando ir√° criar o ficheiro vector_store.pkl na raiz do seu projeto.

Passo 5: Iniciar a F√°brica
Agora, com tudo configurado, inicie todos os servi√ßos em modo interativo para poder ver os logs:

Bash

docker-compose up
Dica: Se quiser que os servi√ßos rodem em segundo plano, use docker-compose up -d.

Passo 6: Aceder √† Interface
Abra o seu navegador e v√° para o endere√ßo do servi√ßo da API:
‚û°Ô∏è http://127.0.0.1:8000/
O index.html deve ser servido automaticamente.

üî¨ Como Desenvolver um Novo "Monstro"
A arquitetura foi desenhada para tornar a cria√ß√£o de novos assistentes um processo simples e padronizado.

Crie a Pasta do Assistente:
Dentro da pasta assistants/, crie um novo diret√≥rio para o seu monstro. Ex: assistants/email_assistant/.

Crie os M√≥dulos de L√≥gica:
Dentro da nova pasta, crie os tr√™s ficheiros essenciais:

schema.py: Defina a estrutura de dados que a sua nova IA deve preencher.

prompt.py: Escreva as instru√ß√µes detalhadas (o prompt) para a nova tarefa.

logic.py: Crie a fun√ß√£o principal (ex: run_email_generation) que executa o fluxo (pode ou n√£o usar RAG).

Registe o Novo Monstro:
No ficheiro main.py, adicione uma entrada no dicion√°rio assistant_map para que o orquestrador saiba como chamar a sua nova cria√ß√£o.

Python

# main.py
assistant_map = {
    "analise_sumula": "assistants.dispensa_assistant",
    "gerar_email": "assistents.email_assistant" # Novo monstro
}
Ajuste a Interface:
Se necess√°rio, adicione novas op√ß√µes no index.html para que os utilizadores possam selecionar e interagir com o novo assistente.